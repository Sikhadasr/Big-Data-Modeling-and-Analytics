{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word Count MapReduce Program in Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Use Pyspark to read an input file and count frequency of unique keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d521b96f28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of Pride and Prejudice, by Jane Austen',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or',\n",
       " 're-use it under the terms of the Project Gutenberg License included']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"Filepath\\\\Text1.txt\")\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get all the words from one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Project', 'Gutenberg', 'EBook', 'of']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words= lines.flatMap(lambda x:x.split(\" \"))\n",
    "words.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Define function cleandata for following:\n",
    "\n",
    "1. Convert all words to lowercase\n",
    "\n",
    "2. Remove all double quotes \n",
    "\n",
    "3. Special characters{\",\", \".\", \";\", \"?\"} to be ignored and removed \n",
    "   from the END of the words such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata(x):\n",
    "    x= x.strip().lower().replace('\"','')\n",
    "    char_list = [\",\", \".\", \";\", \"?\"]\n",
    "    if  len(x) > 0 and x[-1] in char_list:\n",
    "        x = x[:-1]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function cleandata on words rdd and return clean_words rdd after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'project', 'gutenberg', 'ebook', 'of']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words = words.map(lambda x: cleandata(x))\n",
    "clean_words.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final_words rdd to ignore any word of length less than 3 from clean_words rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'project', 'gutenberg', 'ebook', 'pride']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_words = clean_words.filter(lambda x: len(x)>=3)\n",
    "final_words.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate key value pairs with each word as key and 1 as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1), ('project', 1), ('gutenberg', 1), ('ebook', 1), ('pride', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs =final_words.map(lambda x: (x,1))\n",
    "pairs.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create freq rdd from pairs rdd with reducebykey method to get key(word), value(frequency) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('project', 83),\n",
       " ('gutenberg', 24),\n",
       " ('ebook', 10),\n",
       " ('pride', 45),\n",
       " ('jane', 252)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq =pairs.reduceByKey(lambda x, y:x+y)\n",
    "freq.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of 10 given words& their frequency using lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('advantage', [33]),\n",
       " ('book', [14]),\n",
       " ('mistake', [6]),\n",
       " ('dancing', [20]),\n",
       " ('gutenberg', [24]),\n",
       " ('astonishment', [30]),\n",
       " ('hill', [9]),\n",
       " ('yesterday', [12]),\n",
       " ('the', [4480]),\n",
       " ('fox', [])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist =[\"advantage\", \"book\",\"mistake\", \"dancing\", \"gutenberg\", \"astonishment\" ,\"hill\", \"yesterday\", \"the\", \"fox\"]\n",
    "lst = []\n",
    "for i in wordlist:\n",
    "    lst.append((i, freq.lookup(i)))      \n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create word_filtered rdd to put back list of words & their frequency to a rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('advantage', [33]),\n",
       " ('book', [14]),\n",
       " ('mistake', [6]),\n",
       " ('dancing', [20]),\n",
       " ('gutenberg', [24]),\n",
       " ('astonishment', [30]),\n",
       " ('hill', [9]),\n",
       " ('yesterday', [12]),\n",
       " ('the', [4480]),\n",
       " ('fox', [])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_filtered_rdd = sc.parallelize(lst,1)\n",
    "word_filtered_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function println() to print both the word & its fequency in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def println(x):\n",
    "    if len(x[1]) == 0:\n",
    "        final_str = str(x[0]) + \" \" + \"0\"\n",
    "    else:\n",
    "        final_str = str(x[0]) + \" \" + \"\".join(str(x[1][0]))\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advantage 33',\n",
       " 'book 14',\n",
       " 'mistake 6',\n",
       " 'dancing 20',\n",
       " 'gutenberg 24',\n",
       " 'astonishment 30',\n",
       " 'hill 9',\n",
       " 'yesterday 12',\n",
       " 'the 4480',\n",
       " 'fox 0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rdd = word_filtered_rdd.map(lambda x: println(x))\n",
    "final_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rdd.saveAsTextFile(\"File path\\FileName.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
